{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\pard\tx720\tx817\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 Stacking: modele est le r\'e9sultat de l\'92entra\'eenement de plusieurs mod\'e8les\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
Bagging: entrainement sur sous ensemble d\'92\'e9chantillon\
Foret al\'e9atoire ajoute un al\'a0\'e9l\'e9as dans la selection des donn\'e9es de l\'92\'e9chantillon=> + de variabilit\'e9\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul \ulc0 R\'e9duit la variance\ulnone \
\
Boosting: on utilize le retour d\'92experience (voir slides)\
Le modele suivant se concentre sur les donn\'e9es mal class\'e9es du mod\'e8le pr\'e9c\'e9dent, (les bien class\'e9es c\'92est bon)\
Les arbres n\'92ont pas le m\'eame poids\
Arbres ayant de meilleurs r\'e9sultats auront plus de poids\
\ul Boosting r\'e9duit le biais\
\
Gradient boosting\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulnone Focalisation sur les r\'e9sidus \
On cr\'e9er un arbre qui apprend des r\'e9sidus, puis notre r\'e9sultat est y_moyen + la sortie de l\'92arbre\
Au final le model prend la valeur moyenne et y ajoute tous les r\'e9sidus\
L\'92arbre qui suit utilize les precedent en leur accordant un poids ( plus grand poids aux bons arbres) \
\
Pour le projet, et TP faire beaucoup d\'92interpr\'e9tation\
Pour le TP, 4 pages c\'92est vraiment pas assez}