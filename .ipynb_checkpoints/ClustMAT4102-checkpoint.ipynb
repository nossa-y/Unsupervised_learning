{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets as datasets\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
    "print('NumPy: {}'.format(np.__version__))\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "X, Y = datasets.make_blobs(centers=5, cluster_std=0.5, random_state=0)\n",
    "\n",
    "# Observe the data that you will manipulate\n",
    "plt.jet() \n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Apply K-means clustering with k=4 then k=5 ***##\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(4, random_state=0) \n",
    "Y_hat = kmeans.fit(X).labels_\n",
    "plt.scatter(X[:,0], X[:,1], c=Y_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** On the figure above, plot the centroids of the resulting clusters ***##\n",
    "plt.scatter(X[:,0], X[:,1], c=Y_hat, alpha=0.4)\n",
    "mu = kmeans.cluster_centers_\n",
    "plt.scatter(mu[:,0], mu[:,1], s=100, c=np.unique(Y_hat))\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering on MNIST digit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualise MNIST digit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 28*28 MNIST Images\n",
    "from sklearn.datasets import fetch_openml\n",
    "X_digits, Y_digits = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "##**** Take only 10000 instances to shorten runtime of KMeans ***##\n",
    "X_digits = X_digits[0:10000]       \n",
    "Y_digits = Y_digits[0:10000]\n",
    "n_samples, n_features = X_digits.shape\n",
    "n_digits = len(np.unique(Y_digits))\n",
    "\n",
    "\n",
    "##**** Print the number of classes, number of features, number of samples ***##\n",
    "print (n_digits)\n",
    "print (\"n_features: %d\" % n_features)\n",
    "print (\"n_samples: %d\" % n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Visualize the values of Y-digits\n",
    "print(Y_digits)\n",
    "##**** Thus, explain to what refer X_digits and Y_digits ***##\n",
    "\n",
    "##**** Print the number of samples per class ***##\n",
    "X_digits=np.array(X_digits)\n",
    "Y_digits=np.array(Y_digits)\n",
    "Y_int=Y_digits.astype(int)\n",
    "print(\"n_samples per group: %s\" % np.bincount(Y_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Show an exemple of MNIST data ***##\n",
    "p=10\n",
    "plt.imshow(X_digits[p].reshape((28,28)), cmap='gray')\n",
    "print(\"Class: %s\" % Y_digits[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Display twenty images, simultaneously, in grey-scale level and their associated label ***##\n",
    "\n",
    "plt.rc(\"image\", cmap=\"binary\") \n",
    "print(Y_digits[:20])\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.imshow(X_digits[i].reshape(28,28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Apply K-means with K=5 ***##\n",
    "from sklearn.cluster import KMeans\n",
    "n_clusters=10\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=\"k-means++\")\n",
    "model=kmeans.fit(X_digits)\n",
    "\n",
    "print(\"******** KMEANS completed ********\")\n",
    "\n",
    "centroid_digits = model.cluster_centers_\n",
    "\n",
    "# Unsupervised classification of data\n",
    "clusters=model.predict(X_digits) \n",
    "\n",
    "##**** Visualize the centroids ***##\n",
    "plt.figure(figsize=(16,6))\n",
    "for i in range(n_clusters): \n",
    "    plt.subplot(2,n_clusters,i+1)\n",
    "    plt.imshow(centroid_digits[i].reshape(28,28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "\n",
    "##**** Analyze finely the obtained centroids ***##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Plot the Cost Function(Inertia) of the model as a function of K (range : 2 to 13) ***##\n",
    "def plot_inertia(X_digits):\n",
    "    inertia=[]  \n",
    "    K_range=range(2,13)\n",
    "    for k in K_range:\n",
    "        model=KMeans(n_clusters = k).fit(X_digits)\n",
    "        inertia.append(model.inertia_) \n",
    "\n",
    "    plt.figure(figsize=((8,4)))\n",
    "    plt.plot(K_range,inertia, marker='*', color='blue', markersize=5)\n",
    "    plt.xlabel('Nomber of clusters')\n",
    "    plt.ylabel('Intertia J')\n",
    "    plt.show()\n",
    "    \n",
    "plot_inertia(X_digits)   \n",
    "\n",
    "##**** What do you observe ? ***##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the best number K of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Study K (range : 2 to 13) using the clustering metric: Silhouette ***##\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "def plot_silhouette(X_digits):\n",
    "    silhouette=[]\n",
    "    K_range = range(2,13)\n",
    "    for k in K_range:\n",
    "        clusterer = KMeans(n_clusters = k)\n",
    "        cluster_labels = clusterer.fit_predict(X_digits)\n",
    "        silhouette_avg = silhouette_score(X_digits, cluster_labels)\n",
    "        print(\"For k =\", k, \", Average Silhouette Score :\", round(silhouette_avg,4))\n",
    "        silhouette.append(silhouette_avg)\n",
    "    \n",
    "    plt.figure(figsize=((8,4)))\n",
    "    plt.plot(K_range,silhouette, marker='*', markersize=5)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Average Silhouette')\n",
    "    plt.show()\n",
    "\n",
    "plot_silhouette(X_digits)\n",
    "\n",
    "##**** Analyze the obtained curve and what do you conclude on the best value of K ***##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the quality of the clustering based on the original labels using different tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Tool 1 : Use confusion matrix reporting the distribution of the images of a given class (lines) in each cluster (column) ***##\n",
    "conf_matrix=sklearn.metrics.confusion_matrix(Y_int,clusters)\n",
    "print(conf_matrix)\n",
    "\n",
    "##**** Analyze the results and accordingly conclude on the quality of the clustering  ***##\n",
    "##**** Perfom a clustering with the best value of K. Analyze the quality of the clustering ***##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Tool 2 : Infer a label to each resulting cluster based on the most represented label in the cluster ***##\n",
    "\n",
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    \"\"\"\n",
    "    Associates most probable label with each cluster in KMeans model\n",
    "    returns: dictionary of clusters assigned to each label\n",
    "    \"\"\"\n",
    "\n",
    "    inferred_labels = {}\n",
    "    for i in range(kmeans.n_clusters):\n",
    "\n",
    "        # find index of points in cluster\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "\n",
    "        # append actual labels for each point in cluster\n",
    "        labels.append(actual_labels[index])\n",
    "\n",
    "        # determine most common label\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "\n",
    "        # assign the cluster to a value in the inferred_labels dictionary\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            # append the new number to the existing array at this slot\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            # create a new array in this slot\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "        \n",
    "    return inferred_labels  \n",
    "\n",
    "def infer_data_labels(X_labels, cluster_labels):\n",
    "    \"\"\"\n",
    "    Determines label for each array, depending on the cluster it has been assigned to.\n",
    "    returns: predicted labels for each array\n",
    "    \"\"\"\n",
    "    # empty array of len(X)\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
    "    \n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "                \n",
    "    return predicted_labels\n",
    "\n",
    "cluster_labels = infer_cluster_labels(model, Y_int)\n",
    "ig, axs = plt.subplots(1,n_clusters,figsize=(20,20))\n",
    "plt.gray()\n",
    "for i,ax in enumerate(axs.flat):    \n",
    "    for key, value in cluster_labels.items():\n",
    "        if i in value:\n",
    "            ax.set_title('inferred label : {}'.format(key))          \n",
    "    ax.imshow(centroid_digits[i].reshape(28,28))\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "##**** Analyze the inferred labels with the best value of K. Conclude ***##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Tool 3 : Use Entropy metric ***##\n",
    "import scipy\n",
    "entropie = np.zeros(n_clusters)\n",
    "for i in range(n_clusters):\n",
    "    ind = X_digits[clusters==i]\n",
    "    entropie[i] = scipy.stats.entropy(clusters==i)\n",
    "\n",
    "print(\"Entropies=\", entropie)\n",
    "print(\"Average Entropy =\", round(entropie.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indmin = np.argmin(entropie)\n",
    "\n",
    "print(\"Cluster \", indmin,\" presents the lowest entropy value =\",entropie[indmin])\n",
    "imc = X_digits[clusters==indmin]\n",
    "plt.figure(figsize=(7.195, 3.841), dpi=300)\n",
    "for i in range(200):\n",
    " plt.subplot(10,20,i+1)\n",
    " plt.imshow(imc[i,:].reshape([28,28]), cmap='binary')\n",
    " plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indmax = np.argmax(entropie)\n",
    "\n",
    "print(\"Cluster \", indmax,\" presents the highest entropy value =\",entropie[indmax])\n",
    "imc = X_digits[clusters==indmax]\n",
    "plt.figure(figsize=(7.195, 3.841), dpi=300)\n",
    "for i in range(200):\n",
    " plt.subplot(10,20,i+1)\n",
    " plt.imshow(imc[i,:].reshape([28,28]), cmap='binary')\n",
    " plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different number of clusters\n",
    "clu=[2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "\n",
    "for n_clust in clu:\n",
    "    estimator = KMeans(n_clusters = n_clust, init=\"k-means++\",n_init=4)\n",
    "    estimator.fit(X_digits)\n",
    "     \n",
    "    # Determine the inferred label of each cluster\n",
    "    cluster_labels = infer_cluster_labels(estimator, Y_int)\n",
    "    predicted_Y = infer_data_labels(estimator.labels_, cluster_labels)\n",
    "    \n",
    "    # Compute and display the percentage of total good classification \n",
    "    acc=metrics.accuracy_score(Y_int, predicted_Y)\n",
    "    acc=acc*100\n",
    "    print(\"For k =\", n_clust, ', Good distribution of : {}%\\n'.format(round(acc,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-medoïd Clustering on MNIST Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "# TO COMPLETE for clustering MNIST DIGIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model for Clustering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "x, _ = datasets.make_blobs(n_samples=330, centers=5, cluster_std=1.84)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x[:,0], x[:,1])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=5).fit(x)\n",
    "#gm.get_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = gm.means_\n",
    "print(centers)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x[:,0], x[:,1], label=\"data\")\n",
    "plt.scatter(centers[:,0], centers[:,1],c='r', label=\"centers\")\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame \n",
    "pred = gm.predict(x)\n",
    "\n",
    "df = DataFrame({'x':x[:,0], 'y':x[:,1], 'label':pred})\n",
    "groups = df.groupby('label')\n",
    "\n",
    "ig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.scatter(group.x, group.y, label=name)\n",
    "\n",
    "ax.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 6), dpi=80)\n",
    "f.add_subplot(2, 2, 1)\n",
    "\n",
    "for i in range(2, 6):\n",
    " gm = GaussianMixture(n_components=i).fit(x)\n",
    " pred = gm.predict(x)\n",
    " df = DataFrame({'x':x[:,0], 'y':x[:,1], 'label':pred})\n",
    " groups = df.groupby('label')\n",
    " f.add_subplot(2, 2, i-1)\n",
    " for name, group in groups:\n",
    "    plt.scatter(group.x, group.y, label=name, s=8)\n",
    "    plt.title(\"Cluster size:\" + str(i))\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()        \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitation of K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(200, noise=.05, random_state=0)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, cmap='plasma');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete by the application of K-means and DBSCAN methods on such data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means for Compression / Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Read the image 1 ***##\n",
    "OrigImage = io.imread('dog.jpg')\n",
    "io.imshow(OrigImage);\n",
    "print('Shape of the Image : ', OrigImage.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Reshape the image : convert the image into a vector BUT here each element of the vector is in 3D (RGB) ***##\n",
    "rows, cols = OrigImage.shape[0], OrigImage.shape[1]\n",
    "image = OrigImage.reshape(rows * cols, 3)\n",
    "print(image.shape)\n",
    "print(image[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Apply K-Means on the image with K=5, K=10 and K=16 ***##\n",
    "kMeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10)\n",
    "model=kMeans.fit(image)\n",
    "\n",
    "##**** Observe examples of Centeroids in RGB domain (3D) ***##\n",
    "centers = np.asarray(model.cluster_centers_, dtype = np.uint8)\n",
    "#centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels \n",
    "labels = np.asarray(model.labels_, dtype = np.uint8)\n",
    "print(labels.shape)\n",
    "labels = np.reshape(labels, (rows, cols))\n",
    "print(labels.shape)\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Reconstruction of the image based on the segmentation obtained with K-means ***##\n",
    "newImage = np.zeros((rows, cols, 3), dtype = np.uint8)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "            # Assignment of every pixel the rgb color of their label's center \n",
    "            newImage[i, j, :] = centers[labels[i, j], :]\n",
    "#io.imsave('dog-compressed.png', newImage);\n",
    "io.imshow(newImage);\n",
    "newImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##**** Display the original and the compressed images side-by-side for a better comparion ***##\n",
    "##**** Compare with different values of k clusters ***##\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10),subplot_kw=dict(xticks=[], yticks=[]))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax[0].imshow(OrigImage)\n",
    "ax[0].set_title('Original Image', size=10)\n",
    "ax[1].imshow(newImage)\n",
    "ax[1].set_title('Compressed Image', size=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
